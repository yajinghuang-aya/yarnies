{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9I8C-jmJgz7p"
   },
   "source": [
    "# Web Scraping: An Example\n",
    "Mahdi Sadjadi, Data Scientist @ VideoAmp, May 2020\n",
    "\n",
    "This is an introductory example of web scraping box office data in the US using `request` and `BeautifulSoup` packages."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eCCKpH4Hgz7q"
   },
   "source": [
    "## Read the webpage\n",
    "\n",
    "We can read the content of a web page directly into a python object. Using `request` library, we send a request to the server and receive the html content in response. Then we can use `text` method to extract the html."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LQKpsa6qgz7r"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46568"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "box_office_url = \"https://www.the-numbers.com/box-office-chart/daily/2020/01/23\"\n",
    "\n",
    "# Pretend to be a web browser and make a get request of a webpage\n",
    "box_request = requests.get(box_office_url)\n",
    "\n",
    "# The .text returns the text from the request\n",
    "box_html = box_request.text\n",
    "\n",
    "# Parsed string\n",
    "len(box_html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Pmy6AuaNgz71"
   },
   "source": [
    "Print first 200 characters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "COeKvwTJgz72"
   },
   "outputs": [],
   "source": [
    "print (box_html[0:200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_qHIiVeygz77"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r>\n",
      "<td data-sort=\"11\" class=\"data\">11</td>\n",
      "<td data-sort=\"11\" class=\"data\">(11)</td>\n",
      "<td><b><a href=\"/movie/gi-saeng-chung-(South-Korea)-(2019)#tab=box-office\">Parasite</a></b></td>\n",
      "<td><a href=\"/market/distributor/Neon\">Neon</a></td>\n",
      "<td class=\"data\">$218,036</td>\n",
      "<td data-sort=\"-4\" class=\"data chart_down\">-4%</td>\n",
      "<td data-sort=\"28\" class=\"data chart_up\">+28%</td>\n",
      "<td data-sort=\"843\" class=\"data\">843</td>\n",
      "<td data-sort=\"259\" class=\"data chart_grey\">$259</td>\n",
      "<td data-sort=\"28939005\"class=\"data\n"
     ]
    }
   ],
   "source": [
    "print(box_html[20000:20500])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "N8tLPFs6gz8B"
   },
   "source": [
    "## Parse with BeautifulSoup\n",
    "We can directly use the string returned by `request` but it will a long painful process. `BeautifulSoup` allows to decompose the string into html tags. Then we can easily search through the html tree to find the tags we're interested in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "efXrKejngz8C"
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Turn into soup, specify the HTML parser\n",
    "box_soup = BeautifulSoup(box_html, 'html.parser')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WafLTD2mgz8J"
   },
   "source": [
    "Find all tables identified by `table` tag:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "c2iiVPZ2gz8K"
   },
   "outputs": [],
   "source": [
    "all_tables = box_soup.find_all('table')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MXCZ7KXJgz8P"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_tables)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zYPRQCnQgz8W"
   },
   "source": [
    "The first table holds the navigation links and the second table contains the data we need:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6b3XzSEngz8X"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<table class=\"pintable\">\n",
      "<tr>\n",
      "<td class=\"previous\"><a href=\"/box-office-chart/daily/2020/01/22\">← Previous Chart</a></td>\n",
      "<td class=\"index\"><a href=\"/box-office\">Chart Index</a></td>\n",
      "<td class=\"next\"><a href=\"/box-office-chart/daily/2020/01/24\">Next Chart →</a></td>\n",
      "</tr>\n",
      "</table>\n"
     ]
    }
   ],
   "source": [
    "print (all_tables[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pZy2JHpqgz8b"
   },
   "outputs": [],
   "source": [
    "table_with_data = all_tables[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "a9-nQr12gz8p"
   },
   "outputs": [],
   "source": [
    "type(table_with_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "c1oc2_Wjgz8t"
   },
   "outputs": [],
   "source": [
    "#dir(table_with_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Yw6-xZGRgz81"
   },
   "outputs": [],
   "source": [
    "print (table_with_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Sxwjo8Bqgz86"
   },
   "source": [
    "Find all rows containing the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lLV5XT_5gz87"
   },
   "outputs": [],
   "source": [
    "rows = table_with_data.find_all('tr')\n",
    "len(rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PP8i9dDpgz9D"
   },
   "source": [
    "How do we extract the value of each column? \n",
    "Example for a row:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ApKfASTPgz9E"
   },
   "outputs": [],
   "source": [
    "row4 = rows[4]\n",
    "row4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JCAvTTS9gz9I"
   },
   "outputs": [],
   "source": [
    "for item in row4.find_all('td'):\n",
    "    print (f\"Value is = {item.get_text()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Gve0Wpp6gz9Z"
   },
   "outputs": [],
   "source": [
    "def parse_row(row):\n",
    "    \"\"\"\n",
    "    Input: a row object with required data\n",
    "    Output: the value of each column\n",
    "    \"\"\"\n",
    "    \n",
    "    # parse out the text values\n",
    "    items = [item.get_text() for item in row.find_all('td')]\n",
    "    \n",
    "    # post process the item as needed\n",
    "    # See Excercise 3\n",
    "    \n",
    "    return items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xRg52LCrgz9d"
   },
   "outputs": [],
   "source": [
    "parse_row(row4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hT2A5gJ6gz9k"
   },
   "outputs": [],
   "source": [
    "for row in rows[0:4]:\n",
    "    print (parse_row(row))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zaBYY9UIgz9o"
   },
   "source": [
    "## Putting everything together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aaIJwvy7gz9p"
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uzpyQPZlgz9s"
   },
   "outputs": [],
   "source": [
    "columns = [item.get_text() for item in table_with_data.find_all(\"thead\")[0].find_all('th')]\n",
    "columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KMueMWn7gz9w"
   },
   "outputs": [],
   "source": [
    "parsed_data = [parse_row(row) for row in rows]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YKdEkgtcgz9z"
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data=parsed_data, columns=columns)\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bOiq23EQgz94"
   },
   "source": [
    "## Exercises\n",
    "\n",
    "### Exercise 1 (scraping)\n",
    "\n",
    "Look at the `columns` definition and analyze how and why does `table_with_data.find_all(\"thead\")[0].find_all('th')` return the column names?\n",
    "\n",
    "### Exercise 2 (functional programming)\n",
    "\n",
    "It is a best practice to define functions to handle different use cases. For example, we made a table for a single day in the above section. Define a function that receives a date and returns the final table for that date. This function itself is made of other smaller functions which is equivalent to the process I talked about above.\n",
    "\n",
    "### Exercise 3 (string manipulation)\n",
    "Data scraped from pages often need pre-processing and post-processing. Modify `parse_row` (or your equivalent/independent function) to remove the signs (dollar, percentage, ) from data.\n",
    "\n",
    "\n",
    "### Exercise 4 (data handling)\n",
    "\n",
    "It is better to join the dataframe for each day to form a bigger dataset. However, there is no identifier column for dates so if you join two dataframes you don't know where each row came from. Add a column to each dataframe based on their date and then join multiple dataframes to form a final dataframe."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "scraping_insight_2020_May.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
